# Annotation Plan

| Team member | Student number  |
| :--: | :--: |
| Mohammad Ahsan Ghani | 82873100 |
|   Jeremy Yang    |  57353781   |
|  Oksana Necio    |  75493593  |
|   Ruoyao Yin   | 59004859  |

## Type of Annotation
* Our main plan is to do topic classification on question-answer pairs from stackoverflow. We will annotate them  based on keyword bank we come up with. 
* However, we also hold some other thoughts:
1. 5 star helpfulness: we can rate those question-answer pairs from 1 star (not helpful at all), 2 star (somewhat helpful), 3 star (moderate), 4 star (helpful), to 5 star (very helpful). The problem we may encounter is that there may be some answers which are repeated or answers which lead to another answer. We might deal with this either by excluding repeated answers or rating them 2 star (somewhat helpful).
2. 3 star complexity: We rate those question-answer pairs from 1 star (not complex), 2 star (moderate), to 3 star (complex).
3. Binary repeat: we annotate question-answer pairs based on whether they are repeated answers or not.
 

## Annotation Tool:
* We will use Microsoft Excel to create our annotation.

 
## Annotator:
* The team members will be annotators. We considered about using Mechanical Turk. Nevertheless, our data requires a certain level of computer science related knowledge to go through (question-answer pairs from stackoverflow), we decided to do annotation by ourselves. 


## Expectation of Annotation:
* we are annotating 1000 pairs, each doing 500, so weâ€™ll cover 2000 in total, which amounts to 100% double-check.


## Preparation Step:
* To ensure the quality of our annotation, We intend to have annotator training within the group. Since group members comes from various fields, members who have computer science or engineering background will help other members to understand and annotate data.
 
